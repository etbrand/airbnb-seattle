{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "1. [Introduction](#intro)   \n",
    "2. [Quantitative features](#quants)  \n",
    "3. [Categorical features](#cats)  \n",
    "    3.1 [Binary features](#binary)  \n",
    "    3.2 [Ordinal features](#ordinal)  \n",
    "    3.3 [Nominal features with >2 levels](#nominal)  \n",
    "4. [Combining feature sets and rescaling](#combine)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we extract the features we will use to predict property price, impute missing values and rescale to N(0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv('data/listings_train.csv', low_memory=False)\n",
    "listings.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quantitative features\n",
    "<a id='quants'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert percent strings to floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_to_float(pct_column):\n",
    "    \"\"\"Strip punctuation from percents and convert to floats\"\"\"\n",
    "    float_pct = [float(str(pct).replace('%', '')) for pct in pct_column]\n",
    "    return float_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.host_response_rate = pct_to_float(listings.host_response_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `days_as_host` feature from `host_since` column, which is the date the host joined the site:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['days_as_host'] = (pd.to_datetime('2019-07-14') - pd.to_datetime(listings.host_since)).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_features = ['days_as_host', 'host_response_rate', 'host_listings_count', 'accommodates', 'bathrooms', 'bedrooms',\n",
    "                  'beds', 'guests_included', 'minimum_nights', 'number_of_reviews', 'review_scores_rating',\n",
    "                  'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                  'review_scores_communication', 'review_scores_location', 'review_scores_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imp = SimpleImputer()\n",
    "listings[quant_features] = mean_imp.fit_transform(listings[quant_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Categorical features\n",
    "<a id='cats'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Binary features\n",
    "<a id='binary'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode 't' and 'f' to 1 and 0, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_features = ['host_is_superhost', 'instant_bookable']\n",
    "binary_recode = {'t': 1, 'f': 0}\n",
    "listings[binary_features] = listings[binary_features].replace(binary_recode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_imp = SimpleImputer(strategy='most_frequent')\n",
    "listings[binary_features] = freq_imp.fit_transform(listings[binary_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Ordinal features\n",
    "<a id='ordinal'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode levels of ordinal features to preserve their order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['host_response_time', 'cancellation_policy', 'room_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_recode = {'host_response_time':\n",
    "                  {'within an hour': 4, 'within a few hours': 3, 'within a day': 2, 'a few days or more': 1},\n",
    "                  'cancellation_policy':\n",
    "                  {'super_strict_60': 1, 'super_strict_30': 2, 'strict': 3, 'strict_14_with_grace_period': 3, 'moderate': 4, 'flexible': 5},\n",
    "                  'room_type': {'Entire home/apt': 3, 'Private room': 2, 'Shared room': 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.replace(ordinal_recode, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings[ordinal_features] = freq_imp.fit_transform(listings[ordinal_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Nominal features with >2 classes\n",
    "<a id='nominal'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two columns, `amenities` and `host_verifications` contain overlapping classes (i.e., a listing will have multiple amenities and a host may have been verified in multiple ways). We'll create binary features for each class with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_options = []\n",
    "for index, row in listings.iterrows():\n",
    "    listing_amenities = row.amenities.replace('{','').replace('}','').replace('/','_')\n",
    "    listing_amenities = listing_amenities.replace('\\\"','').replace(' ', '_').split(',')\n",
    "    for amenity in listing_amenities:\n",
    "        if amenity not in listings.columns:\n",
    "            listings[amenity] = 0\n",
    "            amenity_options.append(amenity)\n",
    "        listings.at[index, amenity] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_options = []\n",
    "for index, row in listings.iterrows():\n",
    "    listing_verifications = listings.host_verifications.iloc[0].replace('\\'', '').replace('[', '').replace(']', '').split(', ')\n",
    "    for verification in listing_verifications:\n",
    "        if verification not in listings.columns:\n",
    "            listings[verification] = 0\n",
    "            verification_options.append(verification)\n",
    "        listings.at[index, verification] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For features with non-overlapping classes, we can use sklearn's DictVectorizer to convert each class to a binary feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = ['neighbourhood_group_cleansed', 'property_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_dict = listings[nominal_features].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = DictVectorizer(sparse=False)\n",
    "nom_onehot = v.fit_transform(nom_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Combining feature sets and rescaling\n",
    "<a id='combine'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = quant_features + binary_features + ordinal_features + amenity_options + verification_options\n",
    "X_train = np.c_[listings[df_features].values, nom_onehot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the issues we saw in the price data in the `listings.csv` file, we'll use price data from the `calendar.csv` file as our target feature, instead. For now, we'll pick a fixed weekend date that isn't too far beyond when they calendars were scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('data/calendar_train_price.csv')\n",
    "y_train = calendar[calendar.date == '2019-08-03'].set_index('listing_id').loc[listings.index].price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df_features + v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('data/X_train.npy', X_train)\n",
    "#np.save('data/y_train.npy', y_train)\n",
    "#with open('data/feature_names.txt', 'wb') as fp:\n",
    "#    pickle.dump(feature_names, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
